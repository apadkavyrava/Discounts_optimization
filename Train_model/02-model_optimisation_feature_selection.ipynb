{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e2dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92bbac",
   "metadata": {},
   "source": [
    "### Download XGBoost baseline model for optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b4b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import data\n",
    "data = pd.read_csv('../Project_datasets/balanced_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9ba7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dataset preparation\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X = data.drop(['Unnamed: 0', 'Unnamed: 0.1', 'sent_at', 'user_id', 'total_cost_pre_discount_pennies', 'purchase'], axis=1)\n",
    "y = data['purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337beaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# This splits into 70% train, 30% test by default\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cad8230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9358\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      6806\n",
      "           1       0.94      0.93      0.94      6784\n",
      "\n",
      "    accuracy                           0.94     13590\n",
      "   macro avg       0.94      0.94      0.94     13590\n",
      "weighted avg       0.94      0.94      0.94     13590\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6386  420]\n",
      " [ 452 6332]]\n"
     ]
    }
   ],
   "source": [
    "# Create XGBoost classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94797827",
   "metadata": {},
   "source": [
    "### Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0772a22",
   "metadata": {},
   "source": [
    "###### Statistical feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8802622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [2 4 5] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Statistical feature selection (F-test)\n",
    "selector_f = SelectKBest(score_func=f_classif, k=10)  # Select top 10 features\n",
    "X_selected_f = selector_f.fit_transform(X, y)\n",
    "selected_features_f = X.columns[selector_f.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4bad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with F-test selected features: 0.9007\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      4507\n",
      "           1       0.91      0.89      0.90      4553\n",
      "\n",
      "    accuracy                           0.90      9060\n",
      "   macro avg       0.90      0.90      0.90      9060\n",
      "weighted avg       0.90      0.90      0.90      9060\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4123  384]\n",
      " [ 516 4037]]\n"
     ]
    }
   ],
   "source": [
    "# Statistical feature selection (F-test) accuracy\n",
    "\n",
    "# Split data with selected features - use X_selected_f (the actual data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_f, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create XGBoost classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy with F-test selected features: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41321df1",
   "metadata": {},
   "source": [
    "###### XGBoost feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "576277ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost feature importance\n",
    "model_importance = xgb.XGBClassifier(random_state=42)\n",
    "model_importance.fit(X, y)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model_importance.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_features = feature_importance.head(10)['feature'].tolist()\n",
    "X_selected_importance = X[top_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440356c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with XGBoost importance selected features: 0.9276\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      4507\n",
      "           1       0.94      0.92      0.93      4553\n",
      "\n",
      "    accuracy                           0.93      9060\n",
      "   macro avg       0.93      0.93      0.93      9060\n",
      "weighted avg       0.93      0.93      0.93      9060\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4218  289]\n",
      " [ 367 4186]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost feature importance accaracy\n",
    "\n",
    "# Split data with selected features - use X_selected_importance (the actual data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_importance, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create XGBoost classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy with XGBoost importance selected features: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716b40c",
   "metadata": {},
   "source": [
    "###### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfbdc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=xgb.XGBClassifier(random_state=42), n_features_to_select=10)\n",
    "X_selected_rfe = rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "267ed17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with RFE selected features: 0.9232\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      4507\n",
      "           1       0.93      0.91      0.92      4553\n",
      "\n",
      "    accuracy                           0.92      9060\n",
      "   macro avg       0.92      0.92      0.92      9060\n",
      "weighted avg       0.92      0.92      0.92      9060\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4205  302]\n",
      " [ 394 4159]]\n"
     ]
    }
   ],
   "source": [
    "#  Recursive Feature Elimination (RFE) accuracy \n",
    "\n",
    "# Split data with selected features - use X_selected_rfe (the actual data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_rfe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create XGBoost classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy with RFE selected features: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eafd70",
   "metadata": {},
   "source": [
    "#### XGBoost feature importance bcs higher recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd1e8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine selected features and target\n",
    "final_dataset = X_selected_importance.copy()\n",
    "final_dataset['purchase'] = y\n",
    "\n",
    "# Save to CSV\n",
    "final_dataset.to_csv('../Project_datasets/reduced_dataset.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66bbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (Anaconda)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
